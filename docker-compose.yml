services:
  streamlit-app:
    build:
      context: .
      dockerfile: Dockerfile
    image: verbroken-verbinding-prototypes:latest
    container_name: vv-prototype-app
    # No public port mapping; Caddy will reverse proxy to this container
    volumes:
      # Mount for model cache (speeds up repeated loads)
      - huggingface-cache:/root/.cache/huggingface
    environment:
      # Hugging Face token for model access (loaded from .env file)
      - HF_TOKEN=${HF_TOKEN}
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped
    shm_size: '2gb'  # Shared memory for PyTorch

  caddy:
    image: caddy:2
    container_name: vv-caddy
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy-data:/data
      - caddy-config:/config
    depends_on:
      - streamlit-app
    restart: unless-stopped

volumes:
  huggingface-cache:
    driver: local
  caddy-data:
    driver: local
  caddy-config:
    driver: local
